{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[33mWarning:\u001b[0m gcc 14.2.0 is already installed and up-to-date.\n",
      "To reinstall 14.2.0, run:\n",
      "  brew reinstall gcc\n",
      "Collecting lightfm\n",
      "  Using cached lightfm-1.17-cp311-cp311-macosx_14_0_arm64.whl\n",
      "Collecting numpy (from lightfm)\n",
      "  Using cached numpy-2.1.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting scipy>=0.17.0 (from lightfm)\n",
      "  Using cached scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting requests (from lightfm)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting scikit-learn (from lightfm)\n",
      "  Using cached scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->lightfm)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->lightfm)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->lightfm)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->lightfm)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->lightfm)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->lightfm)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl (23.1 MB)\n",
      "Using cached numpy-2.1.1-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, threadpoolctl, numpy, joblib, idna, charset-normalizer, certifi, scipy, requests, scikit-learn, lightfm\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.5.0\n",
      "    Uninstalling threadpoolctl-3.5.0:\n",
      "      Successfully uninstalled threadpoolctl-3.5.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.8.30\n",
      "    Uninstalling certifi-2024.8.30:\n",
      "      Successfully uninstalled certifi-2024.8.30\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "  Attempting uninstall: lightfm\n",
      "    Found existing installation: lightfm 1.17\n",
      "    Uninstalling lightfm-1.17:\n",
      "      Successfully uninstalled lightfm-1.17\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.1 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.1 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n",
      "tensorflow 2.16.2 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed certifi-2024.8.30 charset-normalizer-3.3.2 idna-3.10 joblib-1.4.2 lightfm-1.17 numpy-2.1.1 requests-2.32.3 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "### If after importing lightfm, you get this warning:\n",
    "### \"UserWarning: LightFM was compiled without OpenMP support. \n",
    "### Only a single thread will be used.\"\n",
    "### run the following bash commands to ensure it optimizes its\n",
    "### use of all available CPU cores (much faster training times)\n",
    "!brew install gcc # now check version of gcc (!gcc-14 --version)\n",
    "!CC=gcc-14 pip install --no-binary lightfm lightfm --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "# all_cleaned = pd.read_csv('../data/all_cleaned.csv', usecols=['user_id', 'isbn', 'book_rating', 'mod_book_title', 'mod_book_author', 'genre'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with existing version of data folder\n",
      "Goodreads dataset loaded successfully as books_goodreads\n",
      "Pandas dataframes (books_goodreads, books_big, book, users, ratings) loaded successfully\n",
      "Columns in DataFrames 'users' and 'ratings' renamed\n",
      "You can use the DataFrames 'books' or 'books_big' - they are exactly the same (big) dataset\n",
      "loading books_ratings and books_users_ratings\n",
      "Ready to go!\n"
     ]
    }
   ],
   "source": [
    "%run import_data_.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'user_id' to string to ensure compatibility with LightFM\n",
    "books_users_ratings['user_id'] = books_users_ratings['user_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>user_id</th>\n",
       "      <th>individual_rating</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>nr_ratings</th>\n",
       "      <th>nr_readers</th>\n",
       "      <th>genre</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>annotations</th>\n",
       "      <th>mod_title</th>\n",
       "      <th>mod_author</th>\n",
       "      <th>mod_publisher</th>\n",
       "      <th>image_url_s</th>\n",
       "      <th>image_url_m</th>\n",
       "      <th>image_url_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>590085417</td>\n",
       "      <td>Heidi</td>\n",
       "      <td>Johanna Spyri</td>\n",
       "      <td>102967.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>['Juvenile Fiction', 'Fiction', \"Children's Li...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>Heidi (Fictitious character : Spyri)</td>\n",
       "      <td>heidi</td>\n",
       "      <td>johanna spyri</td>\n",
       "      <td>scholastic</td>\n",
       "      <td>http://images.amazon.com/images/P/0590085417.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0590085417.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0590085417.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>590085417</td>\n",
       "      <td>Heidi</td>\n",
       "      <td>Johanna Spyri</td>\n",
       "      <td>111702.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>['Juvenile Fiction', 'Fiction', \"Children's Li...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>Heidi (Fictitious character : Spyri)</td>\n",
       "      <td>heidi</td>\n",
       "      <td>johanna spyri</td>\n",
       "      <td>scholastic</td>\n",
       "      <td>http://images.amazon.com/images/P/0590085417.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0590085417.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0590085417.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>590085417</td>\n",
       "      <td>Heidi</td>\n",
       "      <td>Johanna Spyri</td>\n",
       "      <td>135473.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>['Juvenile Fiction', 'Fiction', \"Children's Li...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>Heidi (Fictitious character : Spyri)</td>\n",
       "      <td>heidi</td>\n",
       "      <td>johanna spyri</td>\n",
       "      <td>scholastic</td>\n",
       "      <td>http://images.amazon.com/images/P/0590085417.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0590085417.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0590085417.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68107468X</td>\n",
       "      <td>Edgar Allen Poe Collected Poems</td>\n",
       "      <td>Edgar Allan Poe</td>\n",
       "      <td>204964.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>['Poetry']</td>\n",
       "      <td>2020</td>\n",
       "      <td>Bausch &amp; Lombard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>edgar allen poe collected poems</td>\n",
       "      <td>edgar allan poe</td>\n",
       "      <td>bausch lombard</td>\n",
       "      <td>http://images.amazon.com/images/P/068107468X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/068107468X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/068107468X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68107468X</td>\n",
       "      <td>Edgar Allen Poe Collected Poems</td>\n",
       "      <td>Edgar Allan Poe</td>\n",
       "      <td>267830.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>['Poetry']</td>\n",
       "      <td>2020</td>\n",
       "      <td>Bausch &amp; Lombard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>edgar allen poe collected poems</td>\n",
       "      <td>edgar allan poe</td>\n",
       "      <td>bausch lombard</td>\n",
       "      <td>http://images.amazon.com/images/P/068107468X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/068107468X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/068107468X.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isbn                       book_title      book_author   user_id  \\\n",
       "0  590085417                            Heidi    Johanna Spyri  102967.0   \n",
       "1  590085417                            Heidi    Johanna Spyri  111702.0   \n",
       "2  590085417                            Heidi    Johanna Spyri  135473.0   \n",
       "3  68107468X  Edgar Allen Poe Collected Poems  Edgar Allan Poe  204964.0   \n",
       "4  68107468X  Edgar Allen Poe Collected Poems  Edgar Allan Poe  267830.0   \n",
       "\n",
       "   individual_rating  avg_rating  nr_ratings  nr_readers  \\\n",
       "0                8.0         8.0           2           3   \n",
       "1                8.0         8.0           2           3   \n",
       "2                0.0         8.0           2           3   \n",
       "3                8.0         8.0           2           2   \n",
       "4                8.0         8.0           2           2   \n",
       "\n",
       "                                               genre  year_of_publication  \\\n",
       "0  ['Juvenile Fiction', 'Fiction', \"Children's Li...                 2021   \n",
       "1  ['Juvenile Fiction', 'Fiction', \"Children's Li...                 2021   \n",
       "2  ['Juvenile Fiction', 'Fiction', \"Children's Li...                 2021   \n",
       "3                                         ['Poetry']                 2020   \n",
       "4                                         ['Poetry']                 2020   \n",
       "\n",
       "          publisher                           annotations  \\\n",
       "0        Scholastic  Heidi (Fictitious character : Spyri)   \n",
       "1        Scholastic  Heidi (Fictitious character : Spyri)   \n",
       "2        Scholastic  Heidi (Fictitious character : Spyri)   \n",
       "3  Bausch & Lombard                                   NaN   \n",
       "4  Bausch & Lombard                                   NaN   \n",
       "\n",
       "                         mod_title       mod_author   mod_publisher  \\\n",
       "0                            heidi    johanna spyri      scholastic   \n",
       "1                            heidi    johanna spyri      scholastic   \n",
       "2                            heidi    johanna spyri      scholastic   \n",
       "3  edgar allen poe collected poems  edgar allan poe  bausch lombard   \n",
       "4  edgar allen poe collected poems  edgar allan poe  bausch lombard   \n",
       "\n",
       "                                         image_url_s  \\\n",
       "0  http://images.amazon.com/images/P/0590085417.0...   \n",
       "1  http://images.amazon.com/images/P/0590085417.0...   \n",
       "2  http://images.amazon.com/images/P/0590085417.0...   \n",
       "3  http://images.amazon.com/images/P/068107468X.0...   \n",
       "4  http://images.amazon.com/images/P/068107468X.0...   \n",
       "\n",
       "                                         image_url_m  \\\n",
       "0  http://images.amazon.com/images/P/0590085417.0...   \n",
       "1  http://images.amazon.com/images/P/0590085417.0...   \n",
       "2  http://images.amazon.com/images/P/0590085417.0...   \n",
       "3  http://images.amazon.com/images/P/068107468X.0...   \n",
       "4  http://images.amazon.com/images/P/068107468X.0...   \n",
       "\n",
       "                                         image_url_l  \n",
       "0  http://images.amazon.com/images/P/0590085417.0...  \n",
       "1  http://images.amazon.com/images/P/0590085417.0...  \n",
       "2  http://images.amazon.com/images/P/0590085417.0...  \n",
       "3  http://images.amazon.com/images/P/068107468X.0...  \n",
       "4  http://images.amazon.com/images/P/068107468X.0...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_users_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 917916 entries, 0 to 917915\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   isbn                 917916 non-null  object \n",
      " 1   book_title           917916 non-null  object \n",
      " 2   book_author          917916 non-null  object \n",
      " 3   user_id              917916 non-null  object \n",
      " 4   individual_rating    917916 non-null  float64\n",
      " 5   avg_rating           917916 non-null  float64\n",
      " 6   nr_ratings           917916 non-null  int64  \n",
      " 7   nr_readers           917916 non-null  int64  \n",
      " 8   genre                917916 non-null  object \n",
      " 9   year_of_publication  917916 non-null  int64  \n",
      " 10  publisher            917916 non-null  object \n",
      " 11  annotations          438490 non-null  object \n",
      " 12  mod_title            917916 non-null  object \n",
      " 13  mod_author           917916 non-null  object \n",
      " 14  mod_publisher        917916 non-null  object \n",
      " 15  image_url_s          917916 non-null  object \n",
      " 16  image_url_m          917916 non-null  object \n",
      " 17  image_url_l          917916 non-null  object \n",
      "dtypes: float64(2), int64(3), object(13)\n",
      "memory usage: 126.1+ MB\n"
     ]
    }
   ],
   "source": [
    "books_users_ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following cell has been commented out because, in the updated dataset books_users_ratings, the column 'genre' already consists of a list of string values which are the categorized genres according to the same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # categorize genre\n",
    "\n",
    "# # Define the genre mapping\n",
    "# genre_mapping = {\n",
    "#     'fiction': 'Fiction',\n",
    "#     'romance': 'Romance',\n",
    "#     'historical': 'Historical Fiction',\n",
    "#     'thrillers': 'Thriller',\n",
    "#     'suspense': 'Suspense',\n",
    "#     'juvenile fiction': 'Juvenile Fiction',\n",
    "#     'children\\'s literature': 'Children\\'s Literature',\n",
    "#     'guidebooks': 'Guidebooks',\n",
    "#     'poetry': 'Poetry',\n",
    "#     'songs': 'Music',\n",
    "#     'ballads': 'Music',\n",
    "#     'unknown': 'Unknown',\n",
    "#     'error fetching data': 'Unknown'\n",
    "# }\n",
    "\n",
    "# # Function to categorize genres\n",
    "# def categorize_genre(genre):\n",
    "#     genre_lower = genre.lower()\n",
    "#     for keyword, category in genre_mapping.items():\n",
    "#         if keyword in genre_lower:\n",
    "#             return category\n",
    "#     return 'Other'\n",
    "\n",
    "# # Apply the function to the genre column\n",
    "# all_cleaned['categorized_genre'] = all_cleaned['genre'].apply(categorize_genre)\n",
    "\n",
    "# print(all_cleaned[['genre', 'categorized_genre']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183600 entries, 0 to 183599\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   isbn               183600 non-null  object \n",
      " 1   user_id            183600 non-null  object \n",
      " 2   book_rating        183600 non-null  float64\n",
      " 3   mod_book_author    183600 non-null  object \n",
      " 4   mod_book_title     183600 non-null  object \n",
      " 5   categorized_genre  183600 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# dropping the genre column\n",
    "# all_cleaned = all_cleaned.drop(columns=['genre'])\n",
    "# all_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bookmark for Lay: adjust this code for string list type 'genre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "buffer source array is read-only",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 73\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_interactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# Evaluate on the test set\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     auc \u001b[38;5;241m=\u001b[39m auc_score(model, test_interactions, item_features\u001b[38;5;241m=\u001b[39mitem_features)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/neuefische/capstone/matchread/MatchRead/.venv/lib/python3.11/site-packages/lightfm/lightfm.py:550\u001b[0m, in \u001b[0;36mLightFM.fit\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# Discard old results, if any\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_state()\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_partial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43minteractions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neuefische/capstone/matchread/MatchRead/.venv/lib/python3.11/site-packages/lightfm/lightfm.py:655\u001b[0m, in \u001b[0;36mLightFM.fit_partial\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of threads must be 1 or larger.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress(epochs, verbose\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteractions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_finite()\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/neuefische/capstone/matchread/MatchRead/.venv/lib/python3.11/site-packages/lightfm/lightfm.py:696\u001b[0m, in \u001b[0;36mLightFM._run_epoch\u001b[0;34m(self, item_features, user_features, interactions, sample_weight, num_threads, loss)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Call the estimation routines.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 696\u001b[0m     \u001b[43mfit_warp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCSRMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCSRMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositives_lookup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteractions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteractions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteractions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlightfm_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbpr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    713\u001b[0m     fit_bpr(\n\u001b[1;32m    714\u001b[0m         CSRMatrix(item_features),\n\u001b[1;32m    715\u001b[0m         CSRMatrix(user_features),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m    728\u001b[0m     )\n",
      "File \u001b[0;32mlightfm/_lightfm_fast_no_openmp.pyx:787\u001b[0m, in \u001b[0;36mlightfm._lightfm_fast_no_openmp.fit_warp\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstringsource:660\u001b[0m, in \u001b[0;36mView.MemoryView.memoryview_cwrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstringsource:350\u001b[0m, in \u001b[0;36mView.MemoryView.memoryview.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: buffer source array is read-only"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix, coo_matrix\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to build interactions as a sparse matrix\n",
    "def build_interactions(df):\n",
    "    user_ids = df['user_id'].astype('category').cat.codes.values\n",
    "    item_ids = df['isbn'].astype('category').cat.codes.values\n",
    "    ratings = df['individual_rating'].values\n",
    "    return coo_matrix((ratings, (user_ids, item_ids)))\n",
    "\n",
    "# Function to build item features as a sparse matrix\n",
    "def build_item_features(df, feature_index_map):\n",
    "    num_items = len(df['isbn'].unique())\n",
    "    num_features = len(feature_index_map)\n",
    "    feature_matrix = lil_matrix((num_items, num_features))\n",
    "\n",
    "    item_cats = pd.Categorical(df['isbn'])\n",
    "    item_codes = item_cats.codes\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        item_idx = item_cats.codes[df['isbn'] == row['isbn']][0]\n",
    "        features = [row['mod_author']] + (row['genre'] if isinstance(row['genre'], list) else [row['genre']])\n",
    "        feature_indices = [feature_index_map.get(f) for f in features if feature_index_map.get(f) is not None]\n",
    "        feature_matrix[item_idx, feature_indices] = 1\n",
    "\n",
    "    return feature_matrix.tocsr()  # Convert to csr_matrix for efficient operations later\n",
    "\n",
    "# Create feature index map\n",
    "def create_feature_index_map(df):\n",
    "    features = set()\n",
    "    for _, row in df.iterrows():\n",
    "        features.add(row['mod_author'])\n",
    "        if isinstance(row['genre'], list):\n",
    "            features.update(row['genre'])\n",
    "        else:\n",
    "            features.add(row['genre'])\n",
    "    \n",
    "    feature_index_map = {feature: idx for idx, feature in enumerate(sorted(features))}\n",
    "    return feature_index_map\n",
    "\n",
    "# Define LightFM model\n",
    "model = LightFM(loss='warp')\n",
    "\n",
    "# Prepare your data\n",
    "# Assuming books_users_ratings is your DataFrame\n",
    "X = books_users_ratings[['user_id', 'isbn']]\n",
    "y = books_users_ratings['individual_rating']\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = train_test_split(books_users_ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create feature index map\n",
    "feature_index_map = create_feature_index_map(train_data)\n",
    "\n",
    "# Build interaction matrices\n",
    "train_interactions = build_interactions(train_data)\n",
    "test_interactions = build_interactions(test_data)\n",
    "\n",
    "# Build item features\n",
    "item_features = build_item_features(train_data, feature_index_map)\n",
    "\n",
    "# Training with early stopping\n",
    "best_auc = 0\n",
    "patience = 5\n",
    "no_improve = 0\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.fit(train_interactions, item_features=item_features, epochs=1, num_threads=8)\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    auc = auc_score(model, test_interactions, item_features=item_features).mean()\n",
    "    print(f'Epoch {epoch + 1}: AUC = {auc}')\n",
    "    \n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "    \n",
    "    if no_improve >= patience:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "print(f'Final AUC: {best_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'item_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m no_improve \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m---> 57\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(train_interactions, item_features\u001b[38;5;241m=\u001b[39m\u001b[43mitem_features\u001b[49m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Evaluate on the test set\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     auc \u001b[38;5;241m=\u001b[39m auc_score(model, test_interactions, item_features\u001b[38;5;241m=\u001b[39mitem_features)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'item_features' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix, coo_matrix\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "\n",
    "# Function to build interactions as a sparse matrix\n",
    "def build_interactions(df):\n",
    "    user_ids = df['user_id'].astype('category').cat.codes.values\n",
    "    item_ids = df['isbn'].astype('category').cat.codes.values\n",
    "    ratings = df['individual_rating'].values\n",
    "    return coo_matrix((ratings, (user_ids, item_ids)))\n",
    "\n",
    "# Function to build item features as a sparse matrix\n",
    "def build_item_features(df, feature_index_map):\n",
    "    num_items = len(df['isbn'].unique())\n",
    "    num_features = len(feature_index_map)\n",
    "    feature_matrix = lil_matrix((num_items, num_features))\n",
    "\n",
    "    item_cats = pd.Categorical(df['isbn'])\n",
    "    item_codes = item_cats.codes\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        item_idx = item_cats.codes[df['isbn'] == row['isbn']][0]\n",
    "        features = [row['mod_author']] + (row['genre'] if isinstance(row['genre'], list) else [row['genre']])\n",
    "        feature_indices = [feature_index_map.get(f) for f in features if feature_index_map.get(f) is not None]\n",
    "        feature_matrix[item_idx, feature_indices] = 1\n",
    "\n",
    "    return feature_matrix.tocsr()  # Convert to csr_matrix for efficient operations later\n",
    "\n",
    "\n",
    "# Create feature index map\n",
    "def create_feature_index_map(df):\n",
    "    features = set()\n",
    "    for _, row in df.iterrows():\n",
    "        features.add(row['mod_author'])\n",
    "        if isinstance(row['genre'], list):\n",
    "            features.update(row['genre'])\n",
    "        else:\n",
    "            features.add(row['genre'])\n",
    "    \n",
    "    feature_index_map = {feature: idx for idx, feature in enumerate(sorted(features))}\n",
    "    return feature_index_map\n",
    "\n",
    "# Define LightFM model\n",
    "model = LightFM(loss='warp')\n",
    "\n",
    "# Prepare your data\n",
    "# Assuming books_users_ratings is your DataFrame\n",
    "X = books_users_ratings[['user_id', 'isbn']]\n",
    "y = books_users_ratings['individual_rating']\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(books_users_ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create feature index map\n",
    "feature_index_map = create_feature_index_map(train_data)\n",
    "\n",
    "# Build interaction matrices\n",
    "train_interactions = build_interactions(train_data)\n",
    "test_interactions = build_interactions(test_data)\n",
    "\n",
    "# Build item features\n",
    "item_features = build_item_features(train_data, feature_index_map)\n",
    "\n",
    "# Train the LightFM model on the training fold\n",
    "model.fit(train_interactions, item_features=item_features, epochs=30, num_threads=8)\n",
    "\n",
    "# Evaluate the model using AUC score on the test fold\n",
    "auc = auc_score(model, test_interactions, item_features=item_features).mean()\n",
    "\n",
    "print(f'AUC: {auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LightFM model\n",
    "###############(loss='warp') # 'warp' loss functions are good for finding relevant results \n",
    "                             # be it for implicit interactions (e.g. clicks or views)\n",
    "                             # or explicit ones (ratings), and they're efficient\n",
    "                             # Other options were:\n",
    "                             # 1. 'logistic': slower and would give recommendations that the\n",
    "                             # user is expected to like, but it may \"overfit to their taste\"\n",
    "                             # causing a more bubble / echo chamber kind of recommendations\n",
    "                             # 2. 'bpr': good for implicit interactions (not explicit ratings)\n",
    "                             # so it would be a waste of the data we have for ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m interaction_tuples \u001b[38;5;241m=\u001b[39m [(x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m books_users_ratings[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misbn\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Build weights array from individual ratings by matching interaction tuples\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mbooks_users_ratings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbooks_users_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbooks_users_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43misbn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindividual_rating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minteraction_tuples\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create item features by combining author and genres\u001b[39;00m\n\u001b[1;32m     20\u001b[0m item_features \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbuild_item_features(\n\u001b[1;32m     21\u001b[0m     [(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misbn\u001b[39m\u001b[38;5;124m'\u001b[39m], [row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmod_author\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m+\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m books_users_ratings\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[1;32m     22\u001b[0m )\n",
      "Cell \u001b[0;32mIn[24], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m interaction_tuples \u001b[38;5;241m=\u001b[39m [(x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m books_users_ratings[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misbn\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Build weights array from individual ratings by matching interaction tuples\u001b[39;00m\n\u001b[1;32m     14\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([books_users_ratings\u001b[38;5;241m.\u001b[39mloc[(books_users_ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m u) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m---> 15\u001b[0m                                             (\u001b[43mbooks_users_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43misbn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m), \n\u001b[1;32m     16\u001b[0m                                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindividual_rating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m     17\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m u, i \u001b[38;5;129;01min\u001b[39;00m interaction_tuples])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create item features by combining author and genres\u001b[39;00m\n\u001b[1;32m     20\u001b[0m item_features \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbuild_item_features(\n\u001b[1;32m     21\u001b[0m     [(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misbn\u001b[39m\u001b[38;5;124m'\u001b[39m], [row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmod_author\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m+\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m books_users_ratings\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/neuefische/capstone/matchread/MatchRead/.venv/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neuefische/capstone/matchread/MatchRead/.venv/lib/python3.11/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neuefische/capstone/matchread/MatchRead/.venv/lib/python3.11/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/neuefische/capstone/matchread/MatchRead/.venv/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/neuefische/capstone/matchread/MatchRead/.venv/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "# Build the interaction matrix with user-item pairs\n",
    "(interactions, _) = dataset.build_interactions(\n",
    "    [(x[0], x[1]) for x in books_users_ratings[['user_id', 'isbn']].values]\n",
    ")\n",
    "\n",
    "# Retrieve the user-item pairs for ratings\n",
    "interaction_tuples = [(x[0], x[1]) for x in books_users_ratings[['user_id', 'isbn']].values]\n",
    "\n",
    "# Build weights array from individual ratings by matching interaction tuples\n",
    "weights = np.array([books_users_ratings.loc[(books_users_ratings['user_id'] == u) & \n",
    "                                            (books_users_ratings['isbn'] == i), \n",
    "                                            'individual_rating'].values[0] \n",
    "                    for u, i in interaction_tuples])\n",
    "\n",
    "# Create item features by combining author and genres\n",
    "item_features = dataset.build_item_features(\n",
    "    [(row['isbn'], [row['mod_author']] + row['genre']) for _, row in books_users_ratings.iterrows()]\n",
    ")\n",
    "\n",
    "# Define the LightFM model using the logistic loss function for explicit feedback\n",
    "model = LightFM(loss='logistic')\n",
    "\n",
    "# Train the model on the interactions matrix with item features and the individual ratings as weights\n",
    "model.fit(interactions, item_features=item_features, sample_weight=weights, epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     16634.0\n",
       "1     87141.0\n",
       "2    169736.0\n",
       "3    208406.0\n",
       "4    230496.0\n",
       "Name: user_id, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cleaned.user_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recommend_books function\n",
    "def recommend_books(model, interactions, user_id, user_mapping, item_mapping, isbn_info, num_recommendations=5):\n",
    "    # Ensure the user_id is a string\n",
    "    user_id = str(user_id)\n",
    "\n",
    "    # Check if the user_id exists in the user mapping\n",
    "    if user_id not in user_mapping:\n",
    "        raise ValueError(f\"User ID {user_id} is not found in the dataset.\")\n",
    "\n",
    "    # Get the internal index for the user_id\n",
    "    user_idx = user_mapping[user_id]\n",
    "\n",
    "    # Predict scores for all items for the given user\n",
    "    scores = model.predict(user_idx, np.arange(interactions.shape[1]))\n",
    "\n",
    "    # Get the indices of the top scores\n",
    "    top_items = np.argsort(-scores)[:num_recommendations]\n",
    "\n",
    "    # Map the indices back to ISBNs and fetch their title and author\n",
    "    recommended_books = []\n",
    "    for item in top_items:\n",
    "        isbn = list(item_mapping.keys())[list(item_mapping.values()).index(item)]\n",
    "        book_info = isbn_info.get(isbn, {'mod_book_title': 'Unknown Title', 'mod_book_author': 'Unknown Author'})\n",
    "        recommended_books.append({'isbn': isbn, 'title': book_info['mod_book_title'], 'author': book_info['mod_book_author']})\n",
    "\n",
    "    return recommended_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISBN: 1883938813, Title: the ghost dance insurrection a jazzman novel, Author: jack random\n",
      "ISBN: 1878093401, Title: marvin composes a tea and other humorous stories, Author: judith hunt\n",
      "ISBN: 1878093398, Title: the ghostly bell ringer and other mysteries, Author: highlights for children\n",
      "ISBN: 679721886, Title: the woman warrior memoirs of a girlhood among ghosts, Author: maxine hong kingston\n",
      "ISBN: 1863733671, Title: on writing books for children, Author: jenny wagner\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_id_to_recommend = '16634.0'  # Replace with an actual user_id from your dataset\n",
    "\n",
    "try:\n",
    "    # Generate recommendations\n",
    "    recommended_books = recommend_books(model, interactions, user_id_to_recommend, user_mapping, item_mapping, isbn_info)\n",
    "    \n",
    "    # Display the recommended books with titles and authors\n",
    "    for book in recommended_books:\n",
    "        print(f\"ISBN: {book['isbn']}, Title: {book['title']}, Author: {book['author']}\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
